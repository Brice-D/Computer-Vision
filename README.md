# Image Classification


### Projektbeschreibung

Bei diesem Projekt geht es darum mit dem Datensatz "Fruits-360" (bei Kaggle zu finden) den Einfluss von Hyperparametern auf ein Model darzustellen.
Daf√ºr wurde als L√∂sungsansatz "Transfer Learning" ausgew√§hlt. Es wird sp√§ter mehr darauf eingegangen. 

### Fruits-360

<p align="center">
	<img src="images/6_100.jpg">
</p>

[fruits-360](https://www.kaggle.com/moltean/fruits)

Dieser Datensatz besteht aus 90483 Obst-Bilder, die in 131 Klassen (Avocado, Apfel, Kirschen etc.) unterteilt sind. Diese ganze Bilder w√ºrden in 3 Verzeichnisse verteilt, das erste enth√§lt Bilder f√ºr das Training (67692 Bilder), das n√§chste enth√§lt Bilder f√ºr das Testen (22688) und das letzte 103 Bilder auf denen mehreren Obst zu sehen sind. Das letztere Verzeichnis wird jedoch w√§hrend dieser Arbeit nicht verwendet. Die Bilder haben eine Gr√∂√üe von 100x100 Pixel und der Datensatz wurde f√ºr das letzte Mal am 18. Mai 2020 aktualisiert. 

### √Ñhnliche Arbeiten 

Es gibt auf Kaggle eine Menge Arbeiten, die auf diesem Datensatz basiert und es wurde schon eine Genauigkeit von 98% erreicht. Aus diesem Grund ist der Fokus dieser Arbeit nicht eine bessere Accuracy zu erreichen sondern Model zu trainieren mit unterschiedlichen Parametern und zu beobachten wie die ausgew√§hlte Parameter auf das Ergebnis einwirken und falls ungewollte Fehler auftreten, diese zu korrigieren.

### Transfer Learning 

Bei **Transfer Learning** wird ein schon trainiertes Model f√ºr eine spezifische T√§tigkeit verwendet und dieses auf eine √§hnliche T√§tigkeit angewendet.
Diese Optimierung erm√∂glicht es bei der neuen T√§tigkeit eine schnelle L√∂sung und √∂fter eine bessere L√∂sung f√ºr erreichen.
Diese Methode basiert auf 3 Schritte when man ein schon trainiertes Model weiterverwenden will: 
  - Base Model ausw√§hlen: ein schon trainiertes Model soll ausgewh√§hlt werden, am bestens ein Model, das schon mit √§hnlichen Daten wie die neuen Daten trainiert         wurde. 
  - Wiederverwendung des ausgew√§hlten Model: das ausgew√§hlte Model kann dann f√ºr die neue T√§tigekeit eingesetzt werden. Bei dem Einsatz kann das ganze Model ohne 
    weitere √Ñnderung oder mit √Ñnderungen verwendet werden.
  - Bei dem letzten Schritt geht es darum, das m√∂del zu verbessern, um ein besseres Ergebnis zu erreichen. 

Transfer Learning ist n√ºtzlich wenn der Entwickler Zeit sparen m√∂chte, nicht genug Daten hat und eine bessere Perfotmanz erzielen m√∂chte. 

### ResNet50 

Da Transfer learning als L√∂sungsansatz ausgew√§hlt wurde, wird ResNet50 als Base-Model f√ºr diese Arbeit eingesetzt.

ResNet50 ist eine CNN bestehend aus 50 Layers. Das Frameworks keras stellt ein schon trainiertes Model von ResNet50 zur Verf√ºgung, dieses Model wurde mit dem Datensatz **ImageNet** trainiert. Dieses erzielte eine Top-1 Genauigkeit von 75% und eine Top-5 Genauigkeit von 92%.

### Implementierung

Es wurden insgesamt 6 Modele basierend auf ResNet50 trainiert, die Modele wurden nach und nach verbessert, um bessere Ergebnisse zu erzielen in dem Hyperparameter immer angepasst wurden. Die Plot von allen trainierten Modellen werden hier dargestellt und erkl√§rt.
Zu allen Modelen wurden vie neue Layers hinzugef√ºgt:
- Zwei Dense Layer, mit "relu" als Aktivierungsfunktion, einmal 512 und 256 Units f√ºr die Dimension des Outputs 
- zwischen diesen Dense() Layers sind Dropout() Layers mit einer Rate von 25%
- Der Output Layer ist ebensfalls ein Dense() mit "softmax" als Aktivierungsfunktion und 131 Units, weil die Datens√§tze √ºber 131 Klassen verf√ºgt. Softmax ist immer
  Softmax ist die Funktion, die am bestens passt f√ºr eine Klassifiezierung von mehr als 2 Klassen.
  
## Model 1

Beim ersten Training wurde das ResNet50 Model geladen, der letzte Layers deaktiviert "freeze" und die anderen Layers des Models so gesetzt, dass diese nicht trainiert werden. 

Das Ergebnis des ersten Trainings ist im unten stehenden Bild zu sehen. 

<p align="center">
	<img src="images/Test1.jpeg">
</p>

Wie auf dem Bild zu sehen ist, hat das Model nicht wirklich gelernt, weil die Accuracy f√ºr die Validation Bilder nicht mal 1% erreicht hat. Das erste Model wird mit den Testbildern evaluiert und ergibt eine Genauigkeit von 0,71%. Von den 22688 Testbildern k√∂nnen nur 163 Bilder richtig erkannt werden. (very bad result üò¢ )

## Model 2

Hier ging es darum alle Layers von ResNet50 10 Epochen zu trainieren.

<p align="center">
	<img src="images/Test2.jpeg">
</p>

Wie dem Bild zu entnehmen ist, konnte hier ein besseres Ergebnis erreicht werden. Jedoch merkt man das es zwischen den Epochen [2 4] und [6 9] zu eineim m√∂glichen Overfitting kommt, weil in diesen Bereichen die Loss gr√∂√üer wird. 
Beim n√§chsten Ansatz wird versucht das Problem zu l√∂sen. 

## Model 3

Das Problem des Overfittings, das taucht beim zweiten Model wollen wir hier l√∂sen. Das Problem taucht auf wenn das trainierte Model eine schlechte Genauigkeit ergibt mit neuen Datens√§tze, einfach erkl√§rt: training loss << validation loss. 

Es gibt mehrere Methoden das Overfitting zu vermeiden (hier werden nur 2 zwei einfachsten erw√§hnt)
- Das Model mit mehr Daten trainieren
- Early stopping: hier geht es darum das Model mit weningen Epochen zu trainieren. Bis zu einem bestimmten Punkt wird das Model verbessert, Nach diesem Punkt kann     die F√§higkeit des Modells zur Verallgemeinerung jedoch nachlassen, wenn es beginnt, die Trainingsdaten zu √ºberlagern. Die Idee ist dann das Model nur bis zu diesem Punkt zu trainieren. 

<p align="center">
	<img src="images/Test3.jpeg">
</p>













    
